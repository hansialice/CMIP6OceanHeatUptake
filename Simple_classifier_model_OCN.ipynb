{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fc07816",
   "metadata": {},
   "source": [
    "# A simple classification model for Ocean Heat Uptake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730ff963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e20d556",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4773a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfls = xr.open_dataset('data/CMIP6_allmodels.hfls.NA.piC.FFT.OHUlabel.112022.nc')\n",
    "hfss = xr.open_dataset('data/CMIP6_allmodels.hfss.NA.piC.FFT.OHUlabel.112022.nc')\n",
    "pr = xr.open_dataset('data/CMIP6_allmodels.pr.NA.piC.FFT.OHUlabel.112022.nc')\n",
    "psl = xr.open_dataset('data/CMIP6_allmodels.psl.NA.piC.FFT.OHUlabel.112022.nc')\n",
    "tas = xr.open_dataset('data/CMIP6_allmodels.tas.NA.piC.FFT.OHUlabel.112022.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c634f50",
   "metadata": {},
   "source": [
    "## Assign labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a36dead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = hfls.model_OHU.data\n",
    "target = pd.DataFrame(labels)\n",
    "\n",
    "target.columns = ['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c4f7ab",
   "metadata": {},
   "source": [
    "We are converting the numerical labels to categories. <4 = low (assigned '0'), 4-8 is medium (assigned '1') and >8 is high (assigned '2'). Eventually, we have the map this to AMOC index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9354bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 4, 8]\n",
    "names = [0, 1, 2]\n",
    "\n",
    "# 0 i low, 1 is medium, 2 is high\n",
    "\n",
    "d = dict(enumerate(names, 1))\n",
    "target['ocn_cat'] = np.vectorize(d.get)(np.digitize(target['labels'], bins))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe16474",
   "metadata": {},
   "source": [
    "## Classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c7a68",
   "metadata": {},
   "source": [
    "Ocean heat uptake is ONE value. Aggregating all the locations together to train on one number might not be a good idea, so this is a workaround.\n",
    "\n",
    "The function below takes in a single lat, lon location, trains a classifier for that location on different model ensembles and tests the accuracy. It can be used in two ways: \n",
    "- Use the function to deduce accuracy for one location\n",
    "- Use the function in a loop to deduce accuracies for all the locations to understand which location(s) better predict Ocean Heat Uptake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf7808a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6dd39e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ocn_classification(lat, lon):\n",
    "    \n",
    "    set_seed(42)\n",
    "    \n",
    "    tas_npy = tas.tas.data[:,:,lat,lon]\n",
    "    hfls_npy = hfls.hfls.data[:,:,lat,lon]\n",
    "    hfss_npy = hfss.hfss.data[:,:,lat,lon]\n",
    "    pr_npy = pr.pr.data[:,:,lat,lon]\n",
    "    psl_npy = psl.psl.data[:,:,lat,lon]\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    scaler_tas = scaler.fit(tas_npy)\n",
    "    norm_tas = scaler_tas.transform(tas_npy)\n",
    "\n",
    "    scaler_hfls = scaler.fit(hfls_npy)\n",
    "    norm_hfls = scaler_hfls.transform(hfls_npy)\n",
    "\n",
    "    scaler_pr = scaler.fit(pr_npy)\n",
    "    norm_pr = scaler_pr.transform(pr_npy)\n",
    "\n",
    "    scaler_psl = scaler.fit(psl_npy)\n",
    "    norm_psl = scaler_psl.transform(psl_npy)\n",
    "\n",
    "    scaler_hfss = scaler.fit(hfss_npy)\n",
    "    norm_hfss = scaler_hfss.transform(hfss_npy)\n",
    "    \n",
    "    data = []\n",
    "    data.append(np.expand_dims(norm_tas, axis=2))\n",
    "    data.append(np.expand_dims(norm_hfls, axis=2))\n",
    "    data.append(np.expand_dims(norm_hfss, axis=2))\n",
    "    data.append(np.expand_dims(norm_pr, axis=2))\n",
    "    data.append(np.expand_dims(norm_psl, axis=2))\n",
    "    data = np.concatenate(data, axis = 2)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target.ocn_cat, test_size=0.1, random_state=42, stratify=target.ocn_cat)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.4, random_state=42, stratify=y_train)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(601,5)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', mode='auto', restore_best_weights=True, verbose=0, patience=0)\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=10, verbose=0, validation_data=(X_val,y_val) , callbacks=[es])\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=0)\n",
    "    \n",
    "    return test_acc\n",
    "    \n",
    "    #print('Test accuracy for Latitude {} and Longitude {} is {}'.format(lat, lon, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f51e72b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6000000238418579\n"
     ]
    }
   ],
   "source": [
    "## One location\n",
    "\n",
    "print(ocn_classification(26,102))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d22f3c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiple locations--assign an empty matrix first, and run the function in a loop\n",
    "## Usually it takes a long time to go through all the locations and it kills the kernel\n",
    "## it might be a good practice to 'split' the locations into different for loops for efficient usage\n",
    "## for now I am assigning just a small number to demonstrate\n",
    "\n",
    "lat_max = 4 #36 (max lat of this problem)\n",
    "lon_max = 4 #111 (max lon of this problem)\n",
    "pred_ocn = np.zeros((lat_max,lon_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e84f260e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lat {} Lon {} 0 0\n",
      "Lat {} Lon {} 0 1\n",
      "Lat {} Lon {} 0 2\n",
      "Lat {} Lon {} 0 3\n",
      "Lat {} Lon {} 1 0\n",
      "Lat {} Lon {} 1 1\n",
      "Lat {} Lon {} 1 2\n",
      "Lat {} Lon {} 1 3\n",
      "Lat {} Lon {} 2 0\n",
      "Lat {} Lon {} 2 1\n",
      "Lat {} Lon {} 2 2\n",
      "Lat {} Lon {} 2 3\n",
      "Lat {} Lon {} 3 0\n",
      "Lat {} Lon {} 3 1\n",
      "Lat {} Lon {} 3 2\n",
      "Lat {} Lon {} 3 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for lat in range(0,lat_max):\n",
    "    for lon in range(0,lon_max):\n",
    "        print('Lat {} Lon {}', lat, lon)\n",
    "        pred_ocn[lat][lon] = ocn_classification(lat,lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0f2420cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55000001, 0.5       , 0.5       , 0.55000001],\n",
       "       [0.44999999, 0.40000001, 0.5       , 0.55000001],\n",
       "       [0.55000001, 0.5       , 0.60000002, 0.55000001],\n",
       "       [0.44999999, 0.55000001, 0.5       , 0.5       ]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ocn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f1982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
