{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "described-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel = use CMIP6 AWS\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "import matplotlib\n",
    "import matplotlib.animation as animation\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.util import add_cyclic_point\n",
    "import warnings\n",
    "import matplotlib.path as mpath\n",
    "import intake\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import proplot as pplt\n",
    "from numba import jit\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "surprised-ceiling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACCESS-CM2' 'ACCESS-ESM1-5' 'CESM2' 'CESM2-FV2' 'CESM2-WACCM'\n",
      " 'CESM2-WACCM-FV2' 'CanESM5' 'E3SM-1-0' 'FGOALS-g3' 'GISS-E2-1-G'\n",
      " 'GISS-E2-2-G' 'INM-CM4-8' 'MIROC6' 'MPI-ESM-1-2-HAM' 'MPI-ESM1-2-HR'\n",
      " 'MPI-ESM1-2-LR' 'MRI-ESM2-0' 'SAM0-UNICON']\n"
     ]
    }
   ],
   "source": [
    "catalog = intake.open_esm_datastore('https://cmip6-pds.s3.amazonaws.com/pangeo-cmip6.json')\n",
    "#query = dict(variable_id = [\"rsds\",\"rsus\",\"rlds\",\"rlus\",\"hfss\",\"hfls\"], table_id = \"Amon\",\\\n",
    "#             experiment_id = ['historical', 'ssp585'])\n",
    "query = dict(variable_id = [\"msftmz\"],table_id=\"Omon\",\\\n",
    "             experiment_id = ['piControl', 'abrupt-4xCO2'])\n",
    "res = catalog.search(require_all_on=[\"source_id\"],**query)\n",
    "models = res.df['source_id'].unique()\n",
    "print((res.df['source_id'].unique()))\n",
    "#Other msft* variables aren't available, so this is probably the dataset to use.\n",
    "#Decent collection of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "paperback-suite",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piControl, ACCESS-CM2\n",
      "(6000, 50, 300)\n",
      "piControl, ACCESS-ESM1-5\n",
      "(12000, 50, 300)\n",
      "piControl, CESM2\n",
      "(14400, 61, 395)\n",
      "piControl, CESM2-FV2\n",
      "(6000, 61, 395)\n",
      "piControl, CESM2-WACCM\n",
      "(5988, 61, 395)\n",
      "piControl, CESM2-WACCM-FV2\n",
      "(6000, 61, 395)\n",
      "piControl, CanESM5\n",
      "(12000, 45, 290)\n",
      "piControl, E3SM-1-0\n",
      "(6000, 60, 180)\n",
      "piControl, FGOALS-g3\n",
      "(8388, 31, 316)\n",
      "piControl, GISS-E2-1-G\n",
      "(4212, 40, 180)\n",
      "piControl, GISS-E2-2-G\n",
      "(1812, 40, 180)\n",
      "piControl, INM-CM4-8\n",
      "(6372, 33, 181)\n",
      "piControl, MIROC6\n",
      "(9600, 61, 180)\n",
      "piControl, MPI-ESM-1-2-HAM\n",
      "(12000, 41, 180)\n",
      "piControl, MPI-ESM1-2-HR\n",
      "(6000, 41, 180)\n",
      "piControl, MPI-ESM1-2-LR\n",
      "(12000, 41, 180)\n",
      "piControl, MRI-ESM2-0\n",
      "(8412, 61, 362)\n",
      "piControl, SAM0-UNICON\n",
      "(8388, 61, 395)\n"
     ]
    }
   ],
   "source": [
    "#set up dictionaries\n",
    "nyr = 150\n",
    "ntime = nyr*12\n",
    "dict_piC_AMOC = {}\n",
    "\n",
    "lats_AMOC = {}\n",
    "depth_AMOC = {}\n",
    "\n",
    "#set up AWS filesystem access\n",
    "fs_s3 = s3fs.S3FileSystem(anon=True)\n",
    "myvars = [\"msftmz\"] #(time, basin, lev, lat)\n",
    "\n",
    "for imodel in enumerate(models):\n",
    "    print(\"piControl, \"+imodel[1])\n",
    "    for ivar in range(0,len(myvars)):\n",
    "        res = catalog.search(source_id=imodel[1], variable_id=myvars[ivar],\\\n",
    "                             experiment_id=\"piControl\", table_id=\"Omon\")\n",
    "        #print(res.df['zstore'][0])\n",
    "        mapper = fs_s3.get_mapper(res.df['zstore'][0])\n",
    "        ds = xr.open_zarr(mapper, consolidated=True)\n",
    "        #print(ds)\n",
    "        try:\n",
    "            lats_AMOC[imodel[1]] = ds.lat\n",
    "            depth_AMOC[imodel[1]] = ds.lev\n",
    "        except:\n",
    "            print(\"Latitude or depth error\")\n",
    "        try:\n",
    "            print(np.shape(ds[myvars[ivar]].isel(basin=0)))\n",
    "            dict_piC_AMOC[imodel[1]+\"_\"+myvars[ivar]]=ds[myvars[ivar]].isel(basin=0)[0:ntime,:,:]\n",
    "        except (AttributeError, KeyError):\n",
    "            print(myvars[ivar]+\" not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "affiliated-relay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 50, 300)\n",
      "(1800, 50, 300)\n",
      "(1800, 61, 395)\n",
      "(1800, 61, 395)\n",
      "(1800, 61, 395)\n",
      "(1800, 61, 395)\n",
      "(1800, 45, 290)\n",
      "(1800, 60, 180)\n",
      "(1800, 31, 316)\n",
      "(1800, 40, 180)\n",
      "(1800, 40, 180)\n",
      "(1800, 33, 181)\n",
      "(1800, 61, 180)\n",
      "(1800, 41, 180)\n",
      "(1800, 41, 180)\n",
      "(1800, 41, 180)\n",
      "(1800, 61, 362)\n",
      "(1800, 61, 395)\n"
     ]
    }
   ],
   "source": [
    "for key in dict_piC_AMOC:\n",
    "    print(np.shape(dict_piC_AMOC[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "confirmed-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMOCindMax_piC = {}\n",
    "AMOCindLoc_piC = {}\n",
    "for i in enumerate(models):\n",
    "    latmod = lats_AMOC[i[1]]\n",
    "    depthmod = depth_AMOC[i[1]]\n",
    "    latmesh, depthmesh = np.meshgrid(latmod, depthmod)\n",
    "    #print(latmesh)\n",
    "    #print(depthmesh)\n",
    "    MOCmod_piC = dict_piC_AMOC[i[1]+\"_msftmz\"]\n",
    "    MOCmod_piC = np.where(np.isnan(MOCmod_piC),0.,MOCmod_piC)\n",
    "    if i[1]==\"E3SM-1-0\":\n",
    "        MOCmod_piC = MOCmod_piC*1.e-6\n",
    "    else:\n",
    "        MOCmod_piC = MOCmod_piC*1.e-9\n",
    "    myMask = np.where((latmesh>30.)&(latmesh<70.)&(depthmesh>300.)&(depthmesh<2000.), 1., 0.)\n",
    "    myAMOCindMax = np.zeros([1800])\n",
    "    for j in range(0,1800):\n",
    "        myAMOCindMax[j] = np.max(MOCmod_piC[j,:,:]*myMask)\n",
    "    AMOCindMax_piC[i[1]] = myAMOCindMax\n",
    "    inds = np.unravel_index((np.mean(MOCmod_piC,axis=0)*myMask).argmax(),np.shape(MOCmod_piC[0,:,:]))\n",
    "    myAMOCindLoc = np.zeros([1800])\n",
    "    for j in range(0,1800):\n",
    "        myAMOCj = MOCmod_piC[j,:,:]\n",
    "        myAMOCindLoc[j] = myAMOCj[inds]\n",
    "    AMOCindLoc_piC[i[1]]=myAMOCindLoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "brilliant-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "timevec = np.linspace(0.,1799.,1800)\n",
    "#detrend and remove seasonal cycle\n",
    "for i in enumerate(models):\n",
    "    myAMOCindLoc0 = AMOCindLoc_piC[i[1]]\n",
    "    myAMOCindMax0 = AMOCindMax_piC[i[1]]\n",
    "    myAMOCindLoc = np.zeros([1800])\n",
    "    myAMOCindMax = np.zeros([1800])\n",
    "    for j in range(0,12):\n",
    "        myAMOCindLoc[j::12] = myAMOCindLoc0[j::12]-np.mean(myAMOCindLoc0[j::12])\n",
    "        myAMOCindMax[j::12] = myAMOCindMax0[j::12]-np.mean(myAMOCindMax0[j::12])\n",
    "    m,b=np.polyfit(timevec,myAMOCindLoc,1)\n",
    "    myAMOCindLoc = myAMOCindLoc-timevec*m\n",
    "    m,b=np.polyfit(timevec,myAMOCindMax,1)\n",
    "    myAMOCindMax = myAMOCindMax-timevec*m\n",
    "    AMOCindLoc_piC[i[1]] = myAMOCindLoc\n",
    "    AMOCindMax_piC[i[1]] = myAMOCindMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "imported-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make np array, and turn into xarray dataset\n",
    "AMOCindLoc = np.zeros([len(models),1800])\n",
    "AMOCindMax = np.zeros([len(models),1800])\n",
    "for i in enumerate(models):\n",
    "    AMOCindLoc[i[0],:] = AMOCindLoc_piC[i[1]]\n",
    "    AMOCindMax[i[0],:] = AMOCindMax_piC[i[1]]\n",
    "    \n",
    "ds_AMOCLoc = xr.Dataset({\"AMOCindex\":((\"models\",\"t\"),AMOCindLoc)},\n",
    "                        coords = {\n",
    "                            \"models\": models,\n",
    "                            \"t\": np.linspace(0.,1799/12,1800)\n",
    "                        },)\n",
    "ds_AMOCMax = xr.Dataset({\"AMOCindex\":((\"models\",\"t\"),AMOCindMax)},\n",
    "                        coords = {\n",
    "                            \"models\": models,\n",
    "                            \"t\": np.linspace(0.,1799/12,1800)\n",
    "                        },)\n",
    "\n",
    "os.remove(\"/net/aeolus/aura/hansingh/CMIP6.AMOCindex.Control.loc.062022.nc\")\n",
    "os.remove(\"/net/aeolus/aura/hansingh/CMIP6.AMOCindex.Control.max.062022.nc\")\n",
    "ds_AMOCLoc.to_netcdf(\"/net/aeolus/aura/hansingh/CMIP6.AMOCindex.Control.loc.062022.nc\")\n",
    "ds_AMOCMax.to_netcdf(\"/net/aeolus/aura/hansingh/CMIP6.AMOCindex.Control.max.062022.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acting-wrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (models: 18, t: 1800)\n",
      "Coordinates:\n",
      "  * models     (models) object 'ACCESS-CM2' 'ACCESS-ESM1-5' ... 'SAM0-UNICON'\n",
      "  * t          (t) float64 0.0 0.08333 0.1667 0.25 ... 149.7 149.8 149.8 149.9\n",
      "Data variables:\n",
      "    AMOCindex  (models, t) float64 2.333 3.095 2.064 ... -1.72 -2.052 -4.272\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (models: 18, t: 1800)\n",
      "Coordinates:\n",
      "  * models     (models) object 'ACCESS-CM2' 'ACCESS-ESM1-5' ... 'SAM0-UNICON'\n",
      "  * t          (t) float64 0.0 0.08333 0.1667 0.25 ... 149.7 149.8 149.8 149.9\n",
      "Data variables:\n",
      "    AMOCindex  (models, t) float64 1.533 2.098 8.726 ... -1.725 -2.06 -4.224\n"
     ]
    }
   ],
   "source": [
    "print(ds_AMOCLoc)\n",
    "print(ds_AMOCMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "confused-headset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piControl, ACCESS-CM2\n",
      "piControl, ACCESS-ESM1-5\n",
      "piControl, CESM2\n",
      "piControl, CESM2-FV2\n",
      "piControl, CESM2-WACCM\n",
      "piControl, CESM2-WACCM-FV2\n",
      "piControl, CanESM5\n",
      "piControl, E3SM-1-0\n",
      "piControl, FGOALS-g3\n",
      "piControl, GISS-E2-1-G\n",
      "piControl, GISS-E2-2-G\n",
      "piControl, INM-CM4-8\n",
      "piControl, MIROC6\n",
      "piControl, MPI-ESM-1-2-HAM\n",
      "piControl, MPI-ESM1-2-HR\n",
      "piControl, MPI-ESM1-2-LR\n",
      "piControl, MRI-ESM2-0\n",
      "piControl, SAM0-UNICON\n"
     ]
    }
   ],
   "source": [
    "#for same set of models, create time series of psl, hfss, hfls, tas as [model, time, lat, lon]\n",
    "#note that longitude dimension needs to be in terms of [-180,180]\n",
    "catalog = intake.open_esm_datastore('https://cmip6-pds.s3.amazonaws.com/pangeo-cmip6.json')\n",
    "\n",
    "dict_piC = {}\n",
    "\n",
    "lats = {}\n",
    "lons = {}\n",
    "\n",
    "#set up AWS filesystem access\n",
    "fs_s3 = s3fs.S3FileSystem(anon=True)\n",
    "myvars = [\"hfls\",\"hfss\",\"tas\",\"psl\"]\n",
    "\n",
    "for imodel in enumerate(models):\n",
    "    print(\"piControl, \"+imodel[1])\n",
    "    for ivar in range(0,len(myvars)):\n",
    "        res = catalog.search(source_id=imodel[1], variable_id=myvars[ivar],\\\n",
    "                             experiment_id=\"piControl\", table_id=\"Amon\")\n",
    "        #print(res.df['zstore'][0])\n",
    "        mapper = fs_s3.get_mapper(res.df['zstore'][0])\n",
    "        ds = xr.open_zarr(mapper, consolidated=True)\n",
    "        if ivar==0:\n",
    "            try:\n",
    "                lats[imodel[1]] = ds.lat\n",
    "                lons[imodel[1]] = ds.lon\n",
    "            except AttributeError:\n",
    "                ds = ds.rename({\"latitude\":\"lat\", \"longitude\":\"lon\"})\n",
    "                lats[imodel[1]] = ds.lat\n",
    "                lons[imodel[1]] = ds.lon\n",
    "        try:\n",
    "            dict_piC[imodel[1]+\"_\"+myvars[ivar]]=ds[myvars[ivar]][:1800,:,:]\n",
    "        except (AttributeError, KeyError):\n",
    "            print(\"Not enough years\")\n",
    "            ds = ds.rename({\"latitude\":\"lat\", \"longitude\":\"lon\"})\n",
    "            dict_piC[imodel[1]+\"_\"+myvars[ivar]]=ds[myvars[ivar]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "central-monitoring",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ACCESS-CM2\n",
      "(1800, 144, 192)\n",
      "(1800, 144, 192)\n",
      "(1800, 144, 192)\n",
      "(1800, 144, 192)\n",
      "Working on ACCESS-ESM1-5\n",
      "(1800, 145, 192)\n",
      "(1800, 145, 192)\n",
      "(1800, 145, 192)\n",
      "(1800, 145, 192)\n",
      "Working on CESM2\n",
      "(1800, 192, 288)\n",
      "(1800, 192, 288)\n",
      "(1800, 192, 288)\n",
      "(1800, 192, 288)\n",
      "Working on CESM2-FV2\n",
      "(1800, 96, 144)\n",
      "(1800, 96, 144)\n",
      "(1800, 96, 144)\n",
      "(1800, 96, 144)\n",
      "Working on CESM2-WACCM\n",
      "(1800, 192, 288)\n",
      "(1800, 192, 288)\n",
      "(1800, 192, 288)\n",
      "(1800, 192, 288)\n",
      "Working on CESM2-WACCM-FV2\n",
      "(1800, 96, 144)\n",
      "(1800, 96, 144)\n",
      "(1800, 96, 144)\n",
      "(1800, 96, 144)\n",
      "Working on CanESM5\n",
      "(1800, 64, 128)\n",
      "(1800, 64, 128)\n",
      "(1800, 64, 128)\n",
      "(1800, 64, 128)\n",
      "Working on E3SM-1-0\n",
      "(1800, 180, 360)\n",
      "(1800, 180, 360)\n",
      "(1800, 180, 360)\n",
      "(1800, 180, 360)\n",
      "Working on FGOALS-g3\n",
      "(1800, 80, 180)\n",
      "(1800, 80, 180)\n",
      "(1800, 80, 180)\n",
      "(1800, 80, 180)\n",
      "Working on GISS-E2-1-G\n",
      "(1800, 90, 144)\n",
      "(1800, 90, 144)\n",
      "(1800, 90, 144)\n",
      "(1800, 90, 144)\n",
      "Working on GISS-E2-2-G\n",
      "(1800, 90, 144)\n",
      "(1800, 90, 144)\n",
      "(1800, 90, 144)\n",
      "(1800, 90, 144)\n",
      "Working on INM-CM4-8\n",
      "(1800, 120, 180)\n",
      "(1800, 120, 180)\n",
      "(1800, 120, 180)\n",
      "(1800, 120, 180)\n",
      "Working on MIROC6\n",
      "(1800, 128, 256)\n",
      "(1800, 128, 256)\n",
      "(1800, 128, 256)\n",
      "(1800, 128, 256)\n",
      "Working on MPI-ESM-1-2-HAM\n",
      "(1800, 96, 192)\n",
      "(1800, 96, 192)\n",
      "(1800, 96, 192)\n",
      "(1800, 96, 192)\n",
      "Working on MPI-ESM1-2-HR\n",
      "(1800, 192, 384)\n",
      "(1800, 192, 384)\n",
      "(1800, 192, 384)\n",
      "(1800, 192, 384)\n",
      "Working on MPI-ESM1-2-LR\n",
      "(1800, 96, 192)\n",
      "(1800, 96, 192)\n",
      "(1800, 96, 192)\n",
      "(1800, 96, 192)\n",
      "Working on MRI-ESM2-0\n",
      "(1800, 160, 320)\n",
      "(1800, 160, 320)\n",
      "(1800, 160, 320)\n",
      "(1800, 160, 320)\n",
      "Working on SAM0-UNICON\n",
      "(1800, 192, 288)\n",
      "(1800, 192, 288)\n",
      "(1800, 192, 288)\n",
      "(1800, 192, 288)\n"
     ]
    }
   ],
   "source": [
    "#rotate grids to [-180,180]\n",
    "#meshgrid of region of interest\n",
    "lons_rot = {}\n",
    "piC_rot = {}\n",
    "\n",
    "for i in enumerate(models):\n",
    "    print(\"Working on \"+i[1])\n",
    "    #rotate longitudes\n",
    "    mylon0 = lons[i[1]]\n",
    "    nlon0 = len(mylon0)\n",
    "    mylon = np.zeros([nlon0])\n",
    "    zeroind = int((np.abs(mylon0-180.)).argmin())\n",
    "    n0to180 = nlon0-zeroind+1\n",
    "    n181to360 = nlon0-n0to180\n",
    "    mylon[0:nlon0-zeroind] = mylon0[zeroind:]-360.\n",
    "    mylon[nlon0-zeroind:] = mylon0[0:zeroind]\n",
    "    lons_rot[i[1]] = mylon\n",
    "    for ivar in enumerate(myvars):\n",
    "        myfield0 = dict_piC[i[1]+\"_\"+ivar[1]]\n",
    "        myfield = np.zeros(np.shape(myfield0))\n",
    "        myfield[:,:,0:nlon0-zeroind] = myfield0[:,:,zeroind:]\n",
    "        myfield[:,:,nlon0-zeroind:] = myfield0[:,:,0:zeroind]\n",
    "        piC_rot[i[1]+\"_\"+ivar[1]] = myfield\n",
    "        print(np.shape(piC_rot[i[1]+\"_\"+ivar[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "associate-atmosphere",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ACCESS-CM2, hfls\n",
      "Working on ACCESS-CM2, hfss\n",
      "Working on ACCESS-CM2, tas\n",
      "Working on ACCESS-CM2, psl\n",
      "Working on ACCESS-ESM1-5, hfls\n",
      "Working on ACCESS-ESM1-5, hfss\n",
      "Working on ACCESS-ESM1-5, tas\n",
      "Working on ACCESS-ESM1-5, psl\n",
      "Working on CESM2, hfls\n",
      "Working on CESM2, hfss\n",
      "Working on CESM2, tas\n",
      "Working on CESM2, psl\n",
      "Working on CESM2-FV2, hfls\n",
      "Working on CESM2-FV2, hfss\n",
      "Working on CESM2-FV2, tas\n",
      "Working on CESM2-FV2, psl\n",
      "Working on CESM2-WACCM, hfls\n",
      "Working on CESM2-WACCM, hfss\n",
      "Working on CESM2-WACCM, tas\n",
      "Working on CESM2-WACCM, psl\n",
      "Working on CESM2-WACCM-FV2, hfls\n",
      "Working on CESM2-WACCM-FV2, hfss\n",
      "Working on CESM2-WACCM-FV2, tas\n",
      "Working on CESM2-WACCM-FV2, psl\n",
      "Working on CanESM5, hfls\n",
      "Working on CanESM5, hfss\n",
      "Working on CanESM5, tas\n",
      "Working on CanESM5, psl\n",
      "Working on E3SM-1-0, hfls\n",
      "Working on E3SM-1-0, hfss\n",
      "Working on E3SM-1-0, tas\n",
      "Working on E3SM-1-0, psl\n",
      "Working on FGOALS-g3, hfls\n",
      "Working on FGOALS-g3, hfss\n",
      "Working on FGOALS-g3, tas\n",
      "Working on FGOALS-g3, psl\n",
      "Working on GISS-E2-1-G, hfls\n",
      "Working on GISS-E2-1-G, hfss\n",
      "Working on GISS-E2-1-G, tas\n",
      "Working on GISS-E2-1-G, psl\n",
      "Working on GISS-E2-2-G, hfls\n",
      "Working on GISS-E2-2-G, hfss\n",
      "Working on GISS-E2-2-G, tas\n",
      "Working on GISS-E2-2-G, psl\n",
      "Working on INM-CM4-8, hfls\n",
      "Working on INM-CM4-8, hfss\n",
      "Working on INM-CM4-8, tas\n",
      "Working on INM-CM4-8, psl\n",
      "Working on MIROC6, hfls\n",
      "Working on MIROC6, hfss\n",
      "Working on MIROC6, tas\n",
      "Working on MIROC6, psl\n",
      "Working on MPI-ESM-1-2-HAM, hfls\n",
      "Working on MPI-ESM-1-2-HAM, hfss\n",
      "Working on MPI-ESM-1-2-HAM, tas\n",
      "Working on MPI-ESM-1-2-HAM, psl\n",
      "Working on MPI-ESM1-2-HR, hfls\n",
      "Working on MPI-ESM1-2-HR, hfss\n",
      "Working on MPI-ESM1-2-HR, tas\n",
      "Working on MPI-ESM1-2-HR, psl\n",
      "Working on MPI-ESM1-2-LR, hfls\n",
      "Working on MPI-ESM1-2-LR, hfss\n",
      "Working on MPI-ESM1-2-LR, tas\n",
      "Working on MPI-ESM1-2-LR, psl\n",
      "Working on MRI-ESM2-0, hfls\n",
      "Working on MRI-ESM2-0, hfss\n",
      "Working on MRI-ESM2-0, tas\n",
      "Working on MRI-ESM2-0, psl\n",
      "Working on SAM0-UNICON, hfls\n",
      "Working on SAM0-UNICON, hfss\n",
      "Working on SAM0-UNICON, tas\n",
      "Working on SAM0-UNICON, psl\n"
     ]
    }
   ],
   "source": [
    "#interpolation to ROI grid\n",
    "\n",
    "#define ROI:\n",
    "latmax = 75.\n",
    "latmin = 30.\n",
    "lonmin = -80.\n",
    "lonmax = 30.\n",
    "lat_rg = np.arange(latmin,latmax+1.)\n",
    "lon_rg = np.arange(lonmin,lonmax+1.)\n",
    "lon_rg_mesh,lat_rg_mesh = np.meshgrid(lon_rg,lat_rg)\n",
    "nlon_rg = len(lon_rg)\n",
    "nlat_rg = len(lat_rg)\n",
    "\n",
    "#regrid loop\n",
    "piC_rg = {}\n",
    "for i in enumerate(models):\n",
    "    mylon = lons_rot[i[1]]\n",
    "    mylat = lats[i[1]]\n",
    "    for ivar in enumerate(myvars):\n",
    "        print(\"Working on \"+i[1]+\", \"+ivar[1])\n",
    "        myfield = piC_rot[i[1]+\"_\"+ivar[1]]\n",
    "        myfield_rg = np.zeros([ntime,nlat_rg,nlon_rg])\n",
    "        for itime in range(0,ntime):\n",
    "            myfunc = scipy.interpolate.RectBivariateSpline(mylat,mylon,myfield[itime,:,:])\n",
    "            myfield_rg[itime,:,:] = myfunc(lat_rg,lon_rg)\n",
    "        piC_rg[i[1]+\"_\"+ivar[1]] = myfield_rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "solid-router",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ACCESS-CM2, hfls\n",
      "Working on ACCESS-CM2, hfss\n",
      "Working on ACCESS-CM2, tas\n",
      "Working on ACCESS-CM2, psl\n",
      "Working on ACCESS-ESM1-5, hfls\n",
      "Working on ACCESS-ESM1-5, hfss\n",
      "Working on ACCESS-ESM1-5, tas\n",
      "Working on ACCESS-ESM1-5, psl\n",
      "Working on CESM2, hfls\n",
      "Working on CESM2, hfss\n",
      "Working on CESM2, tas\n",
      "Working on CESM2, psl\n",
      "Working on CESM2-FV2, hfls\n",
      "Working on CESM2-FV2, hfss\n",
      "Working on CESM2-FV2, tas\n",
      "Working on CESM2-FV2, psl\n",
      "Working on CESM2-WACCM, hfls\n",
      "Working on CESM2-WACCM, hfss\n",
      "Working on CESM2-WACCM, tas\n",
      "Working on CESM2-WACCM, psl\n",
      "Working on CESM2-WACCM-FV2, hfls\n",
      "Working on CESM2-WACCM-FV2, hfss\n",
      "Working on CESM2-WACCM-FV2, tas\n",
      "Working on CESM2-WACCM-FV2, psl\n",
      "Working on CanESM5, hfls\n",
      "Working on CanESM5, hfss\n",
      "Working on CanESM5, tas\n",
      "Working on CanESM5, psl\n",
      "Working on E3SM-1-0, hfls\n",
      "Working on E3SM-1-0, hfss\n",
      "Working on E3SM-1-0, tas\n",
      "Working on E3SM-1-0, psl\n",
      "Working on FGOALS-g3, hfls\n",
      "Working on FGOALS-g3, hfss\n",
      "Working on FGOALS-g3, tas\n",
      "Working on FGOALS-g3, psl\n",
      "Working on GISS-E2-1-G, hfls\n",
      "Working on GISS-E2-1-G, hfss\n",
      "Working on GISS-E2-1-G, tas\n",
      "Working on GISS-E2-1-G, psl\n",
      "Working on GISS-E2-2-G, hfls\n",
      "Working on GISS-E2-2-G, hfss\n",
      "Working on GISS-E2-2-G, tas\n",
      "Working on GISS-E2-2-G, psl\n",
      "Working on INM-CM4-8, hfls\n",
      "Working on INM-CM4-8, hfss\n",
      "Working on INM-CM4-8, tas\n",
      "Working on INM-CM4-8, psl\n",
      "Working on MIROC6, hfls\n",
      "Working on MIROC6, hfss\n",
      "Working on MIROC6, tas\n",
      "Working on MIROC6, psl\n",
      "Working on MPI-ESM-1-2-HAM, hfls\n",
      "Working on MPI-ESM-1-2-HAM, hfss\n",
      "Working on MPI-ESM-1-2-HAM, tas\n",
      "Working on MPI-ESM-1-2-HAM, psl\n",
      "Working on MPI-ESM1-2-HR, hfls\n",
      "Working on MPI-ESM1-2-HR, hfss\n",
      "Working on MPI-ESM1-2-HR, tas\n",
      "Working on MPI-ESM1-2-HR, psl\n",
      "Working on MPI-ESM1-2-LR, hfls\n",
      "Working on MPI-ESM1-2-LR, hfss\n",
      "Working on MPI-ESM1-2-LR, tas\n",
      "Working on MPI-ESM1-2-LR, psl\n",
      "Working on MRI-ESM2-0, hfls\n",
      "Working on MRI-ESM2-0, hfss\n",
      "Working on MRI-ESM2-0, tas\n",
      "Working on MRI-ESM2-0, psl\n",
      "Working on SAM0-UNICON, hfls\n",
      "Working on SAM0-UNICON, hfss\n",
      "Working on SAM0-UNICON, tas\n",
      "Working on SAM0-UNICON, psl\n"
     ]
    }
   ],
   "source": [
    "#apply landmask (maybe? or not?)\n",
    "#remove seasonal cycle\n",
    "#detrend\n",
    "piC_fin_mon = {}\n",
    "piC_fin_yr = {}\n",
    "#landmasked version\n",
    "piC_fin_mon_lm = {}\n",
    "piC_fin_yr_lm = {}\n",
    "monthvec = np.linspace(0.,(ntime-1)/12,ntime)\n",
    "yrvec = np.linspace(0.,nyr-1,nyr)\n",
    "\n",
    "#create landmask and put it on ROI grid\n",
    "datadir = \"/net/aeolus/aura/hansingh/SOMClimos/\"\n",
    "myfile = \"SOM_Control.cam5.0030-0059.ann.nc\"\n",
    "deg2rad = np.pi/180.\n",
    "Re = 6.4e6\n",
    "cp = 3850.\n",
    "rho = 1025.\n",
    "myData_C = xr.open_dataset(datadir+myfile, decode_times=False)\n",
    "mylat_cesm = np.array(myData_C.lat)\n",
    "mylon_cesm = np.array(myData_C.lon)\n",
    "landfrac = np.array(myData_C.LANDFRAC[0,:,:])\n",
    "myfunc = scipy.interpolate.RectBivariateSpline(mylat,mylon,landfrac)\n",
    "landfrac_rg = myfunc(lat_rg,lon_rg)\n",
    "landfrac_rg = np.where(landfrac_rg<0.5,0.,landfrac_rg)\n",
    "landfrac_rg = np.where(landfrac_rg>=0.5,1.,landfrac_rg)\n",
    "\n",
    "for i in enumerate(models):\n",
    "    for ivar in enumerate(myvars):\n",
    "        print(\"Working on \"+i[1]+\", \"+ivar[1])\n",
    "        myfield0 = piC_rg[i[1]+\"_\"+ivar[1]]\n",
    "        myfield_mon = np.zeros([ntime,nlat_rg,nlon_rg])\n",
    "        myfield_yr = np.zeros([nyr,nlat_rg,nlon_rg])\n",
    "        #remove seasonal cycle\n",
    "        for imon in range(0,12):\n",
    "            monmean = np.mean(myfield0[imon::12,:,:],axis=0)\n",
    "            myfield_mon[imon::12,:,:] = myfield0[imon::12,:,:]-monmean\n",
    "        #calculate annual means\n",
    "        for iyr in range(0,nyr):\n",
    "            myfield_yr[iyr,:,:] = np.mean(myfield0[iyr*12:(iyr+1)*12,:,:],axis=0)\n",
    "        myfield_yr = myfield_yr-np.mean(myfield_yr,axis=0) #remove mean\n",
    "        #detrend\n",
    "        for ilat in range(0,nlat_rg):\n",
    "            for ilon in range(0,nlon_rg):\n",
    "                slope, yint, rval, pval, exerr = scipy.stats.linregress(monthvec,myfield_mon[:,ilat,ilon])\n",
    "                myfield_mon[:,ilat,ilon] = myfield_mon[:,ilat,ilon]-monthvec*slope\n",
    "                slope, yint, rval, pval, exerr = scipy.stats.linregress(yrvec,myfield_yr[:,ilat,ilon])\n",
    "                myfield_yr[:,ilat,ilon] = myfield_yr[:,ilat,ilon]-yrvec*slope\n",
    "        #put into dicts\n",
    "        piC_fin_mon[i[1]+\"_\"+ivar[1]] = myfield_mon\n",
    "        piC_fin_yr[i[1]+\"_\"+ivar[1]] = myfield_yr\n",
    "        #apply ocean mask\n",
    "        piC_fin_mon_lm[i[1]+\"_\"+ivar[1]] = myfield_mon*(1.-landfrac_rg)\n",
    "        piC_fin_yr_lm[i[1]+\"_\"+ivar[1]] = myfield_yr*(1.-landfrac_rg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "brilliant-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ivar in enumerate(myvars):\n",
    "    mydata = np.zeros([len(models),ntime,nlat_rg,nlon_rg])\n",
    "    for imod in enumerate(models):\n",
    "        mydata[imod[0],:,:,:] = piC_fin_mon[imod[1]+\"_\"+ivar[1]]\n",
    "    ds = xr.Dataset({ivar[1]:((\"models\",\"t\",\"lat\",\"lon\"),mydata)},\n",
    "                   coords={\n",
    "                       \"models\":models,\n",
    "                       \"t\": monthvec,\n",
    "                       \"lat\": lat_rg,\n",
    "                       \"lon\": lon_rg\n",
    "                          },)\n",
    "    ds.to_netcdf(\"/net/aeolus/aura/hansingh/CMIP6.\"+ivar[1]+\".Control.month.062022.nc\")\n",
    "    mydata = np.zeros([len(models),nyr,nlat_rg,nlon_rg])\n",
    "    for imod in enumerate(models):\n",
    "        mydata[imod[0],:,:,:] = piC_fin_yr[imod[1]+\"_\"+ivar[1]]\n",
    "    ds = xr.Dataset({ivar[1]:((\"models\",\"t\",\"lat\",\"lon\"),mydata)},\n",
    "                   coords={\n",
    "                       \"models\":models,\n",
    "                       \"t\": yrvec,\n",
    "                       \"lat\": lat_rg,\n",
    "                       \"lon\": lon_rg\n",
    "                          },)\n",
    "    ds.to_netcdf(\"/net/aeolus/aura/hansingh/CMIP6.\"+ivar[1]+\".Control.annual.062022.nc\")\n",
    "    mydata = np.zeros([len(models),ntime,nlat_rg,nlon_rg])\n",
    "    for imod in enumerate(models):\n",
    "        mydata[imod[0],:,:,:] = piC_fin_mon_lm[imod[1]+\"_\"+ivar[1]]\n",
    "    ds = xr.Dataset({ivar[1]:((\"models\",\"t\",\"lat\",\"lon\"),mydata)},\n",
    "                   coords={\n",
    "                       \"models\":models,\n",
    "                       \"t\": monthvec,\n",
    "                       \"lat\": lat_rg,\n",
    "                       \"lon\": lon_rg\n",
    "                          },)\n",
    "    ds.to_netcdf(\"/net/aeolus/aura/hansingh/CMIP6.\"+ivar[1]+\".Control.OcnOnly.month.062022.nc\")\n",
    "    mydata = np.zeros([len(models),nyr,nlat_rg,nlon_rg])\n",
    "    for imod in enumerate(models):\n",
    "        mydata[imod[0],:,:,:] = piC_fin_yr_lm[imod[1]+\"_\"+ivar[1]]\n",
    "    ds = xr.Dataset({ivar[1]:((\"models\",\"t\",\"lat\",\"lon\"),mydata)},\n",
    "                   coords={\n",
    "                       \"models\":models,\n",
    "                       \"t\": yrvec,\n",
    "                       \"lat\": lat_rg,\n",
    "                       \"lon\": lon_rg\n",
    "                          },)\n",
    "    ds.to_netcdf(\"/net/aeolus/aura/hansingh/CMIP6.\"+ivar[1]+\".Control.OcnOnly.annual.062022.nc\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "latest-terrorist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ACCESS-CM2\n",
      "Working on ACCESS-ESM1-5\n",
      "Working on CESM2\n",
      "Working on CESM2-FV2\n",
      "Working on CESM2-WACCM\n",
      "Working on CESM2-WACCM-FV2\n",
      "Working on CanESM5\n",
      "Working on E3SM-1-0\n",
      "Working on FGOALS-g3\n",
      "Working on GISS-E2-1-G\n",
      "Working on GISS-E2-2-G\n",
      "Working on INM-CM4-8\n",
      "Working on MIROC6\n",
      "Working on MPI-ESM-1-2-HAM\n",
      "Working on MPI-ESM1-2-HR\n",
      "Working on MPI-ESM1-2-LR\n",
      "Working on MRI-ESM2-0\n",
      "**Model not found.\n",
      "Working on SAM0-UNICON\n",
      "ACCESS-CM2\n",
      "ACCESS-ESM1-5\n",
      "CESM2\n",
      "CESM2-FV2\n",
      "CESM2-WACCM\n",
      "CESM2-WACCM-FV2\n",
      "CanESM5\n",
      "E3SM-1-0\n",
      "FGOALS-g3\n",
      "GISS-E2-1-G\n",
      "GISS-E2-2-G\n",
      "INM-CM4-8\n",
      "MIROC6\n",
      "MPI-ESM-1-2-HAM\n",
      "MPI-ESM1-2-HR\n",
      "MPI-ESM1-2-LR\n",
      "MRI-ESM2-0\n",
      "**Not found.\n",
      "SAM0-UNICON\n"
     ]
    }
   ],
   "source": [
    "#Use netcdf files to load dOHU\n",
    "dict_dOHU = {}\n",
    "mydir = \"/net/aeolus/aura/hansingh/CMIP6AWS_data_processed/\"\n",
    "\n",
    "for i in enumerate(models):\n",
    "    imod = i[1]\n",
    "    print(\"Working on \"+imod)\n",
    "    try:\n",
    "        OHU_C = xr.open_dataset(mydir+\"rsds.\"+imod+\".piControl.nc\").rsds-xr.open_dataset(mydir+\"rsus.\"+imod+\".piControl.nc\").rsus+\\\n",
    "                xr.open_dataset(mydir+\"rlds.\"+imod+\".piControl.nc\").rlds-xr.open_dataset(mydir+\"rlus.\"+imod+\".piControl.nc\").rlus-\\\n",
    "                xr.open_dataset(mydir+\"hfss.\"+imod+\".piControl.nc\").hfss-xr.open_dataset(mydir+\"hfls.\"+imod+\".piControl.nc\").hfls\n",
    "        OHU_E = xr.open_dataset(mydir+\"rsds.\"+imod+\".abrupt4XCO2.nc\").rsds-xr.open_dataset(mydir+\"rsus.\"+imod+\".abrupt4XCO2.nc\").rsus+\\\n",
    "                xr.open_dataset(mydir+\"rlds.\"+imod+\".abrupt4XCO2.nc\").rlds-xr.open_dataset(mydir+\"rlus.\"+imod+\".abrupt4XCO2.nc\").rlus-\\\n",
    "                xr.open_dataset(mydir+\"hfss.\"+imod+\".abrupt4XCO2.nc\").hfss-xr.open_dataset(mydir+\"hfls.\"+imod+\".abrupt4XCO2.nc\").hfls\n",
    "        dict_dOHU[imod] = (OHU_E-OHU_C).squeeze()\n",
    "    except:\n",
    "        print(\"**Model not found.\")\n",
    "        \n",
    "#Calculate OHU indices\n",
    "#Calculate Heat Uptake Indices\n",
    "#Calculate global mean and regional heat uptake\n",
    "dict_GM_OHU_anom = {}\n",
    "dict_SHext_OHU_anom = {}\n",
    "dict_NHext_OHU_anom = {}\n",
    "deg2rad = np.pi/180.\n",
    "\n",
    "for i in enumerate(models):\n",
    "    imod = i[1]\n",
    "    try:\n",
    "        mylat = np.array(lats[imod])\n",
    "        print(imod)\n",
    "        coslat = np.cos(deg2rad*mylat)\n",
    "        coslat_SHext = np.where(mylat<-50.,coslat,0.)\n",
    "        coslat_NHext = np.where(mylat>50.,coslat,0.)\n",
    "        mydOHU = dict_dOHU[imod]\n",
    "        dict_GM_OHU_anom[imod] = np.nansum(np.mean(mydOHU, axis=1)*coslat)/np.nansum(coslat)\n",
    "        dict_SHext_OHU_anom[imod] = np.nansum(np.mean(mydOHU, axis=1)*coslat_SHext)/np.nansum(coslat_SHext)\n",
    "        dict_NHext_OHU_anom[imod] = np.nansum(np.mean(mydOHU, axis=1)*coslat_NHext)/np.nansum(coslat_NHext)\n",
    "    except:\n",
    "        print(\"**Not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "entire-electricity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACCESS-CM2': 5.069753901720349, 'ACCESS-ESM1-5': 2.4882552462510663, 'CESM2': 8.839188644119957, 'CESM2-FV2': 9.16785190771157, 'CESM2-WACCM': 8.535441704125132, 'CESM2-WACCM-FV2': 8.869834498690738, 'CanESM5': 4.5455000859568395, 'E3SM-1-0': 3.7530974761661042, 'FGOALS-g3': 4.500549003077796, 'GISS-E2-1-G': 10.009460452837633, 'GISS-E2-2-G': 7.181215819251269, 'INM-CM4-8': 2.035252762553003, 'MIROC6': 5.9347614565180615, 'MPI-ESM-1-2-HAM': 5.033206612744432, 'MPI-ESM1-2-HR': 4.809416286484583, 'MPI-ESM1-2-LR': 4.314390270693941, 'SAM0-UNICON': 9.355502162646175}\n",
      "[ 5.0697539   2.48825525  8.83918864  9.16785191  8.5354417   8.8698345\n",
      "  4.54550009  3.75309748  4.500549   10.00946045  7.18121582  2.03525276\n",
      "  5.93476146  5.03320661  4.80941629  4.31439027         nan  9.35550216]\n"
     ]
    }
   ],
   "source": [
    "print(dict_NHext_OHU_anom)\n",
    "dOHU_NH = np.zeros([len(models)])\n",
    "for i in enumerate(models):\n",
    "    try:\n",
    "        dOHU_NH[i[0]] = dict_NHext_OHU_anom[i[1]]\n",
    "    except:\n",
    "        dOHU_NH[i[0]] = np.nan\n",
    "        \n",
    "print(dOHU_NH)\n",
    "myds = xr.Dataset({\"dOHU\":((\"models\"),dOHU_NH)},\n",
    "                  coords = {\n",
    "                      \"models\": models\n",
    "                  },)\n",
    "#os.remove(\"/net/aeolus/aura/hansingh/CMIP6.OcnHeatUptake.4XCO2.062022.pdf\")\n",
    "myds.to_netcdf(\"/net/aeolus/aura/hansingh/CMIP6_OHUdata/CMIP6.OcnHeatUptake.4XCO2.062022.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-acquisition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMIP6 AWS",
   "language": "python",
   "name": "cmip6aws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
